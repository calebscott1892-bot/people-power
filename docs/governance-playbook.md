# People Power — Governance Playbook (Internal)

**Audience:** maintainers, moderators, and staff reviewers

**Purpose:** Provide a consistent, safety-first process for reviewing reports, taking action, and handling appeals.

> This playbook is operational guidance, not legal advice. Use it alongside the Terms of Service, Content Policy, and Community Guidelines.

---

## 1) Mission & Safety Stance

- **Mission:** Enable community organizing and civic action while protecting users from harm.
- **Safety stance:** Safety and human dignity come first. We remove content and restrict accounts when needed to prevent harm.
- **Neutral platform posture:** We provide tools; we do not endorse movements. Enforcement is based on behavior and policy violations, not viewpoint.
- **Privacy first:** Minimize exposure of personal data. Avoid doxxing amplification (including in moderator notes).

---

## 2) Moderation Pipeline (End-to-End)

### A. Automated signals (intake)
Signals may include: user reports, rate-limit/brigading heuristics, spam patterns, harassment indicators, repeated policy hits, suspicious account activity.

**Goal:** Triage. Automation should *prioritize* review, not finalize punishment on its own.

### B. Human review (decision)
1. **Confirm scope** (what is being reported: movement, comment, message, profile).
2. **Collect context** (surrounding content, timeline, repeated behavior, prior actions).
3. **Policy mapping** (what policy is implicated? Content Policy vs Community Guidelines vs TOS).
4. **Risk assessment**
   - Credible threat of violence / self-harm
   - Harassment intensity and target vulnerability
   - Doxxing / privacy exposure
   - Coordinated manipulation / brigading
   - Illegality (credible facilitation of crime)
5. **Choose action** using the enforcement ladder below.
6. **Record** a concise decision note.

### C. Enforcement (apply)
Possible outcomes include: no action, content removal, warnings, temporary suspension, permanent ban, feature restrictions.

### D. Appeals (review)
Appeals are handled by a reviewer who is not the original decision-maker when possible.

---

## 3) Enforcement Ladder (When To Warn / Suspend / Ban)

### Guiding principles
- Use the **least intrusive** action that reduces risk.
- Prefer **clear, behavior-based** messaging.
- Escalate faster for **high-severity harm**, repeat violations, or evasion.

### A. Warn a user when
- First-time or low-severity violations where education can correct behavior.
- Incivility, borderline harassment, or minor misinformation without imminent harm.
- Good-faith mistakes (e.g., accidental rule break) with quick correction.

**Typical actions:** remove/limit the content + warning + guidance to relevant policy.

### B. Temporarily suspend when
- Repeated policy violations after warning(s).
- Harassment, hate, or targeted abuse that is severe but not an immediate safety emergency.
- Spam / scams / impersonation patterns.
- Ongoing disruption (brigading, coordinated manipulation).

**Typical actions:** content removal + suspension + restriction on posting/messaging after reinstatement.

### C. Permanently ban when
- Credible threats of violence, incitement, or coordination of violent actions.
- Doxxing or stalking behavior, especially repeated or escalatory.
- Sexual exploitation content, grooming, or sexual content involving minors.
- Persistent hate/harassment campaigns or ban evasion.
- Fraud/scams at scale or repeated impersonation after enforcement.

**Approval:** Permanent bans should be reviewed by **two staff reviewers** when feasible, or one staff reviewer + post-hoc audit within 24 hours.

---

## 4) Appeals: How They’re Handled & Documented

### A. What qualifies as an appeal
- User claims a mistake, misunderstanding, lack of context, or false report.
- User provides new evidence (e.g., edited content, context, identity verification).

### B. Appeal process
1. **Acknowledge** receipt (no promises on timing).
2. **Re-evaluate** the evidence and policy mapping.
3. **Check consistency** with prior similar decisions.
4. **Decision**: uphold, modify (reduce/increase), or overturn.

### C. Documentation expectations
Write brief, factual notes:
- What policy was applied
- What evidence was considered
- Why the action was selected
- Any follow-up safeguards (e.g., feature restrictions)

Avoid storing sensitive personal data in notes unless strictly necessary.

---

## 5) Edge Cases & High-Risk Scenarios

### A. Political tension / controversial but legal content
- Focus on **behavior and safety**, not ideology.
- Allow robust debate when it does not cross into harassment, hate, threats, or doxxing.
- Watch for brigading and coordinated manipulation; apply anti-brigading safeguards.

### B. Misinformation
- Distinguish **bad-faith deception** from **good-faith error**.
- Escalate quickly when misinformation creates imminent harm (medical, panic, violence).

### C. Real-world event safety
- If content promotes dangerous offline behavior, prioritize safety interventions.
- If credible imminent harm is present, escalate internally and follow the platform’s emergency cooperation posture described in Terms.

### D. Minors / exploitation risk
- Treat as high priority. Remove and restrict quickly.
- Preserve necessary evidence for internal review without sharing widely.

---

## 6) Reviewer Checklist (Quick)

- What content/action is being reviewed?
- What is the direct harm risk?
- Which policy section applies?
- Is this a repeat pattern?
- Least-invasive effective action?
- Clear user-facing explanation?
- Logged decision notes (brief, factual, privacy-respecting)?

---

## 7) Quality & Consistency

- Run periodic audits on:
  - false positives/negatives
  - repeat offender handling
  - appeal overturn rates
- Keep enforcement consistent across content types (movement vs comment vs profile).
